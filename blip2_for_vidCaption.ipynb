{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aLehav/MLVideoDescriptionResearch/blob/main/blip2_for_vidCaption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Generation of all frames in a video at the rate of 10 per second using opencv. Later on, we can look into different methods of extracting the change-points.\n",
        "\n"
      ],
      "metadata": {
        "id": "i_v2xGl0yJue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# save to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/vidCaptions\")\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/vidCaptions\")\n",
        "\n",
        "\n",
        "# i.e if video of duration 30 seconds, saves 1 frame per second = 30 frames saved in total\n",
        "SAVING_FRAMES_PER_SECOND = 2"
      ],
      "metadata": {
        "id": "KfY39ZXiyToX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349089e0-8b33-4d58-86e6-719622be27f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "GNKeSxcfyga-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_timedelta(td):\n",
        "    \"\"\"Utility function to format timedelta objects in a cool way (e.g 00:00:20.05) \n",
        "    omitting microseconds and retaining milliseconds\"\"\"\n",
        "    result = str(td)\n",
        "    try:\n",
        "        result, ms = result.split(\".\")\n",
        "    except ValueError:\n",
        "        return (result + \".00\").replace(\":\", \"-\")\n",
        "    ms = int(ms)\n",
        "    ms = round(ms / 1e4)\n",
        "    return f\"{result}.{ms:02}\".replace(\":\", \"-\")\n",
        "\n",
        "\n",
        "def get_saving_frames_durations(cap, saving_fps):\n",
        "    \"\"\"A function that returns the list of durations where to save the frames\"\"\"\n",
        "    s = []\n",
        "    # get the clip duration by dividing number of frames by the number of frames per second\n",
        "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "    # use np.arange() to make floating-point steps\n",
        "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
        "        s.append(i)\n",
        "    return s"
      ],
      "metadata": {
        "id": "jQBSC5mzzMpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main function to extract the frames from video."
      ],
      "metadata": {
        "id": "6wtuCi8UzPBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(video_file):\n",
        "    filename, _ = os.path.splitext(video_file)\n",
        "    filename += \"-opencv\"\n",
        "    # make a folder by the name of the video file\n",
        "    if not os.path.isdir(filename):\n",
        "        os.mkdir(filename)\n",
        "    # read the video file    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    # get the FPS of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)\n",
        "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
        "    # get the list of duration spots to save\n",
        "    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n",
        "    # start the loop\n",
        "    count = 0\n",
        "    while True:\n",
        "        is_read, frame = cap.read()\n",
        "        if not is_read:\n",
        "            # break out of the loop if there are no frames to read\n",
        "            break\n",
        "        # get the duration by dividing the frame count by the FPS\n",
        "        frame_duration = count / fps\n",
        "        try:\n",
        "            # get the earliest duration to save\n",
        "            closest_duration = saving_frames_durations[0]\n",
        "        except IndexError:\n",
        "            # the list is empty, all duration frames were saved\n",
        "            break\n",
        "        if frame_duration >= closest_duration:\n",
        "            # if closest duration is less than or equals the frame duration, \n",
        "            # then save the frame\n",
        "            frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n",
        "            cv2.imwrite(os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\"), frame) \n",
        "            \n",
        "            # drop the duration spot from the list, since this duration spot is already saved\n",
        "            try:\n",
        "                saving_frames_durations.pop(0)\n",
        "            except IndexError:\n",
        "                pass\n",
        "        # increment the frame count\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "i08Fz_TyzfTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the functions to extract videos. "
      ],
      "metadata": {
        "id": "XxwVecqvzmkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location = \"qqR6AEXwxoQ.mp4\" # put location of video path here\n",
        "video_file = location\n",
        "main(video_file)"
      ],
      "metadata": {
        "id": "w12HG8nbztC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYgMKV-PuRc3"
      },
      "source": [
        "#### Large RAM is required to load the larger models. Running on GPU can optimize inference speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHeLkIAKuRc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "81673add-5613-4de8-89de-5b8ce0bb27b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b8fe8559471a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'google.colab'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running in Colab.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install salesforce-lavis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    437\u001b[0m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[1;32m    438\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    164\u001b[0m         'A UTF-8 locale is required. Got {}'.format(locale_encoding))\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print('Running in Colab.')\n",
        "    !pip3 install salesforce-lavis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIRiLqCQuRc7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from lavis.models import load_model_and_preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM_B7KRauRc7"
      },
      "source": [
        "#### Load an example image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-fKViWJuRc8"
      },
      "outputs": [],
      "source": [
        "def loadImg(imgPath):\n",
        "  return Image.open(requests.get(imgPath, stream=True).raw).convert('RGB')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05MEVNyyuRc8"
      },
      "outputs": [],
      "source": [
        "# setup device to use\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LevJwVpmuRc9"
      },
      "source": [
        "#### Load pretrained/finetuned BLIP2 captioning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RDR87CzuRc9",
        "outputId": "fedffb5f-183f-42c8-fd2b-efe905412830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'eval'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# we associate a model with its preprocessors to make it easier for inference.\n",
        "model, vis_processors, _ = load_model_and_preprocess(\n",
        "    name=\"blip_caption\", model_type=\"base_coco\", is_eval=True, device=device\n",
        ")\n",
        "\n",
        "# Other available models:\n",
        "# \n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"pretrain_opt2.7b\", is_eval=True, device=device\n",
        "# )\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"pretrain_opt6.7b\", is_eval=True, device=device\n",
        "# )\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"caption_coco_opt2.7b\", is_eval=True, device=device\n",
        "# )\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"caption_coco_opt6.7b\", is_eval=True, device=device\n",
        "# )\n",
        "#\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_t5\", model_type=\"pretrain_flant5xl\", is_eval=True, device=device\n",
        "# )\n",
        "#\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_t5\", model_type=\"caption_coco_flant5xl\", is_eval=True, device=device\n",
        "# )\n",
        "\n",
        "vis_processors.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate text description with the model and save it to a list"
      ],
      "metadata": {
        "id": "LelUVEfknMtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames_dir = location.replace('.mp4', '') + \"-opencv\"\n",
        "fields = [\"Title\", \"Cap1\", \"Cap2\", \"Cap3\"]\n",
        "rows = []\n",
        "for rawImg in os.listdir(frames_dir):\n",
        "  procRaw = Image.open(frames_dir + \"/\" + rawImg).convert(\"RGB\")\n",
        "  image = vis_processors[\"eval\"](procRaw).unsqueeze(0).to(device)\n",
        "  rows.append([rawImg] + model.generate({\"image\": image}, use_nucleus_sampling=True, num_captions=3))"
      ],
      "metadata": {
        "id": "i--BOpQZnhzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save into CSV file in the folder"
      ],
      "metadata": {
        "id": "EAwKqtER3mXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "filename = frames_dir + \"_captions.csv\"\n",
        "\n",
        "with open(filename, 'w') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(fields)\n",
        "  csvwriter.writerows(rows)"
      ],
      "metadata": {
        "id": "APzl-LrC3qP0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}