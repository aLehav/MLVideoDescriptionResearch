{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxH785Q4aHdZ2S0/XPV2vT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9621e98a947f493bb5f9261b6729f29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cfa8ba2084b4252a30bec144741f47c",
              "IPY_MODEL_c7f058613a9c4986b94f9e14361619e2",
              "IPY_MODEL_a9d605dd30d046b484b147b76eb7b982"
            ],
            "layout": "IPY_MODEL_86190fc49cea44b8bdb5362a2b13f04c"
          }
        },
        "4cfa8ba2084b4252a30bec144741f47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9cca933d064e6b9f7491d71e69f721",
            "placeholder": "​",
            "style": "IPY_MODEL_3fc8a46ab9e244bf9ba451b2cbb5762d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "c7f058613a9c4986b94f9e14361619e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eeeddb0a74a44dd962c647ab458b72f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_324ed37beab542f58307f85669d322ab",
            "value": 231508
          }
        },
        "a9d605dd30d046b484b147b76eb7b982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd6739d5206499e84cb2cec48cff707",
            "placeholder": "​",
            "style": "IPY_MODEL_45203b03b8e74dffb19b127ba5437177",
            "value": " 232k/232k [00:00&lt;00:00, 1.29MB/s]"
          }
        },
        "86190fc49cea44b8bdb5362a2b13f04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9cca933d064e6b9f7491d71e69f721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fc8a46ab9e244bf9ba451b2cbb5762d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eeeddb0a74a44dd962c647ab458b72f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "324ed37beab542f58307f85669d322ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddd6739d5206499e84cb2cec48cff707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45203b03b8e74dffb19b127ba5437177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab545785f2754e9094c0bc929da964b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d04f8d7127414227afac83b41d821760",
              "IPY_MODEL_70464cfbc5244403b7bd0e6bdbb0a65b",
              "IPY_MODEL_18594ac7bc244529bc109f3e3f240eb0"
            ],
            "layout": "IPY_MODEL_ca5f447eabb24304b67de37383927b26"
          }
        },
        "d04f8d7127414227afac83b41d821760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00faa5d204e3447bab58f6fbd4686ccd",
            "placeholder": "​",
            "style": "IPY_MODEL_de3d26f4e42846259ecb4f80d8bd4931",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "70464cfbc5244403b7bd0e6bdbb0a65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d315eb1393542bb99da2687a444b653",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfa93a7e03054b7ca5064362e080f428",
            "value": 28
          }
        },
        "18594ac7bc244529bc109f3e3f240eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d1d7f5adc24638bbf9f9cb18fea712",
            "placeholder": "​",
            "style": "IPY_MODEL_c85b0403e1a643559328325691cc52e0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 532B/s]"
          }
        },
        "ca5f447eabb24304b67de37383927b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00faa5d204e3447bab58f6fbd4686ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3d26f4e42846259ecb4f80d8bd4931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d315eb1393542bb99da2687a444b653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa93a7e03054b7ca5064362e080f428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32d1d7f5adc24638bbf9f9cb18fea712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85b0403e1a643559328325691cc52e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a812c56b53a74ad59650c9c766189826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc385a393ea14802bafdbd7da010c31d",
              "IPY_MODEL_0808ba11a5e74b0882b2bab39871f549",
              "IPY_MODEL_bc6b98b3473f4cb49455be0ef0dda8a1"
            ],
            "layout": "IPY_MODEL_1c6c6470fb164e0bb8aa7b5a1dadebd1"
          }
        },
        "cc385a393ea14802bafdbd7da010c31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9b2d33a901b408c9ac81238da952f76",
            "placeholder": "​",
            "style": "IPY_MODEL_a32999de2a4b445b8b62c4671af42619",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0808ba11a5e74b0882b2bab39871f549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_116de93cb712445cab5eb6362dc94c7e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a12f7026702b44f0bd0e636055f8e53a",
            "value": 570
          }
        },
        "bc6b98b3473f4cb49455be0ef0dda8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4180e04fb2b740b3b81d4e25360ff893",
            "placeholder": "​",
            "style": "IPY_MODEL_2b2cd2056706408bae694e9cc2b08ac3",
            "value": " 570/570 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "1c6c6470fb164e0bb8aa7b5a1dadebd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b2d33a901b408c9ac81238da952f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32999de2a4b445b8b62c4671af42619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "116de93cb712445cab5eb6362dc94c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12f7026702b44f0bd0e636055f8e53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4180e04fb2b740b3b81d4e25360ff893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2cd2056706408bae694e9cc2b08ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76fd4a89ed024c56849829d9684dd8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf467985034b4fefb92b5d9d9867f022",
              "IPY_MODEL_c71c86972f914464b2dc078db959f781",
              "IPY_MODEL_e8c3d14869e142fab3b4989e6389c68e"
            ],
            "layout": "IPY_MODEL_f770b05f05ad4c219cff457e57d90fda"
          }
        },
        "cf467985034b4fefb92b5d9d9867f022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e26f685b9834aed9e5e6a415cf64e35",
            "placeholder": "​",
            "style": "IPY_MODEL_6baf63a2a6244322badd78644730cb66",
            "value": "100%"
          }
        },
        "c71c86972f914464b2dc078db959f781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3f9576db5e4da1ba748ece13ab487a",
            "max": 2688144147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49416de57ac84d80b4b480c784285c39",
            "value": 2688144147
          }
        },
        "e8c3d14869e142fab3b4989e6389c68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada4f5fbf8ed447e90301df539e9398f",
            "placeholder": "​",
            "style": "IPY_MODEL_1ea459bc0974456eb3cda2c673a55e86",
            "value": " 2.50G/2.50G [00:42&lt;00:00, 69.4MB/s]"
          }
        },
        "f770b05f05ad4c219cff457e57d90fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e26f685b9834aed9e5e6a415cf64e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6baf63a2a6244322badd78644730cb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3f9576db5e4da1ba748ece13ab487a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49416de57ac84d80b4b480c784285c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ada4f5fbf8ed447e90301df539e9398f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea459bc0974456eb3cda2c673a55e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aLehav/MLVideoDescriptionResearch/blob/main/BEATs_and_BLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Link to BEATs Github](https://github.com/microsoft/unilm/tree/master/beats)\n",
        "\n",
        "[Link to AudioSet](https://ieeexplore-ieee-org.libproxy2.usc.edu/stamp/stamp.jsp?tp=&arnumber=7952261)"
      ],
      "metadata": {
        "id": "_y-nwtAKQLbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3 --quiet\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "import sys\n",
        "import math\n",
        "import cv2\n",
        "import torch\n",
        "import torchaudio\n",
        "import gc\n",
        "import json\n",
        "import os\n",
        "import tarfile\n",
        "import tempfile\n",
        "import boto3\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "from IPython.display import Audio\n",
        "!pip3 install salesforce-lavis --quiet\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from lavis.models import load_model_and_preprocess\n",
        "!git clone https://github.com/microsoft/unilm.git --quiet\n",
        "!ls\n",
        "os.chdir('/content/unilm/beats')\n",
        "# %cd unilm/beats\n",
        "from Tokenizers import TokenizersConfig, Tokenizers\n",
        "from BEATs import BEATs, BEATsConfig\n",
        "os.chdir('../../')\n",
        "# %cd ../../\n",
        "!git clone https://github.com/audioset/ontology.git --quiet\n",
        "os.chdir('/content/ontology')\n",
        "# %cd ontology\n",
        "f = open('ontology.json')\n",
        "ontology = json.load(f)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/MyDrive/video_summarization/')\n",
        "sys.path.append('/content/drive/MyDrive/video_summarization/')\n",
        "# %cd ../drive/MyDrive/video_summarization/\n",
        "anno = pd.read_csv('ydata-tvsum50-anno.tsv', sep='\\t', header=None)\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZcrI8RGLlBT",
        "outputId": "03c77b94-e355-418d-c930-170882fd8d9d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.8/495.8 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.3/202.3 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  unilm\n",
            "Mounted at /content/drive\n",
            "91IHQYk1IQM.mp3\t\t\t\t\t ontology\n",
            "91IHQYk1IQM.mp4\t\t\t\t\t qqR6AEXwxoQ.mp3\n",
            "91IHQYk1IQM.wav\t\t\t\t\t qqR6AEXwxoQ.wav\n",
            "BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt  Tokenizer_iter3_plus_AS2M.pt\n",
            "BEATs_iter3_plus_AS2M.pt\t\t\t ydata-tvsum50-anno.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVING_FRAMES_PER_SECOND = 6"
      ],
      "metadata": {
        "id": "OM4US-sl8QkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions"
      ],
      "metadata": {
        "id": "ElB1GI4_8Ud8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_timedelta(td):\n",
        "    \"\"\"Utility function to format timedelta objects in a cool way (e.g 00:00:20.05) \n",
        "    omitting microseconds and retaining milliseconds\"\"\"\n",
        "    result = str(td)\n",
        "    try:\n",
        "        result, ms = result.split(\".\")\n",
        "    except ValueError:\n",
        "        return (result + \".00\").replace(\":\", \"-\")\n",
        "    ms = int(ms)\n",
        "    ms = round(ms / 1e4)\n",
        "    return f\"{result}.{ms:02}\".replace(\":\", \"-\")\n",
        "\n",
        "\n",
        "def get_saving_frames_durations(cap, saving_fps):\n",
        "    \"\"\"A function that returns the list of durations where to save the frames\"\"\"\n",
        "    s = []\n",
        "    # get the clip duration by dividing number of frames by the number of frames per second\n",
        "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "    # use np.arange() to make floating-point steps\n",
        "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
        "        s.append(i)\n",
        "    return s"
      ],
      "metadata": {
        "id": "nOqXoYC38Xmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main function to extract the frames from video.\n",
        "\n"
      ],
      "metadata": {
        "id": "7RtmKyju8Z0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(video_file):\n",
        "    filename, _ = os.path.splitext(video_file)\n",
        "    filename += \"-opencv\"\n",
        "    # make a folder by the name of the video file\n",
        "    if not os.path.isdir(filename):\n",
        "        os.mkdir(filename)\n",
        "    # read the video file    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    # get the FPS of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)\n",
        "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
        "    # get the list of duration spots to save\n",
        "    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n",
        "    # start the loop\n",
        "    count = 0\n",
        "    while True:\n",
        "        is_read, frame = cap.read()\n",
        "        if not is_read:\n",
        "            # break out of the loop if there are no frames to read\n",
        "            break\n",
        "        # get the duration by dividing the frame count by the FPS\n",
        "        frame_duration = count / fps\n",
        "        try:\n",
        "            # get the earliest duration to save\n",
        "            closest_duration = saving_frames_durations[0]\n",
        "        except IndexError:\n",
        "            # the list is empty, all duration frames were saved\n",
        "            break\n",
        "        if frame_duration >= closest_duration:\n",
        "            # if closest duration is less than or equals the frame duration, \n",
        "            # then save the frame\n",
        "            frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n",
        "            cv2.imwrite(os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\"), frame) \n",
        "            \n",
        "            # drop the duration spot from the list, since this duration spot is already saved\n",
        "            try:\n",
        "                saving_frames_durations.pop(0)\n",
        "            except IndexError:\n",
        "                pass\n",
        "        # increment the frame count\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "5fn3WqHU8deE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the functions to extract videos.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gh40Vv1G8pSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vid_name = \"91IHQYk1IQM\"\n",
        "location = vid_name + \".mp4\" # put location of video path here\n",
        "video_file = location\n",
        "main(video_file)"
      ],
      "metadata": {
        "id": "qE5RmdQH8sYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImg(imgPath):\n",
        "  return Image.open(requests.get(imgPath, stream=True).raw).convert('RGB')   "
      ],
      "metadata": {
        "id": "qEBrQWe11L71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup device to use\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "sXoopsxF1SFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pretrained/finetuned BLIP2 captioning model"
      ],
      "metadata": {
        "id": "ZYp4uUNY1T2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we associate a model with its preprocessors to make it easier for inference.\n",
        "model, vis_processors, _ = load_model_and_preprocess(\n",
        "    name=\"blip_caption\", model_type=\"base_coco\", is_eval=True, device=device\n",
        ")\n",
        "\n",
        "# Other available models:\n",
        "# \n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"pretrain_opt2.7b\", is_eval=True, device=device\n",
        "# )\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"pretrain_opt6.7b\", is_eval=True, device=device\n",
        "# )\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"caption_coco_opt2.7b\", is_eval=True, device=device\n",
        "# )\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_opt\", model_type=\"caption_coco_opt6.7b\", is_eval=True, device=device\n",
        "# )\n",
        "#\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_t5\", model_type=\"pretrain_flant5xl\", is_eval=True, device=device\n",
        "# )\n",
        "#\n",
        "# model, vis_processors, _ = load_model_and_preprocess(\n",
        "#     name=\"blip2_t5\", model_type=\"caption_coco_flant5xl\", is_eval=True, device=device\n",
        "# )\n",
        "\n",
        "vis_processors.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "9621e98a947f493bb5f9261b6729f29f",
            "4cfa8ba2084b4252a30bec144741f47c",
            "c7f058613a9c4986b94f9e14361619e2",
            "a9d605dd30d046b484b147b76eb7b982",
            "86190fc49cea44b8bdb5362a2b13f04c",
            "4b9cca933d064e6b9f7491d71e69f721",
            "3fc8a46ab9e244bf9ba451b2cbb5762d",
            "7eeeddb0a74a44dd962c647ab458b72f",
            "324ed37beab542f58307f85669d322ab",
            "ddd6739d5206499e84cb2cec48cff707",
            "45203b03b8e74dffb19b127ba5437177",
            "ab545785f2754e9094c0bc929da964b4",
            "d04f8d7127414227afac83b41d821760",
            "70464cfbc5244403b7bd0e6bdbb0a65b",
            "18594ac7bc244529bc109f3e3f240eb0",
            "ca5f447eabb24304b67de37383927b26",
            "00faa5d204e3447bab58f6fbd4686ccd",
            "de3d26f4e42846259ecb4f80d8bd4931",
            "3d315eb1393542bb99da2687a444b653",
            "dfa93a7e03054b7ca5064362e080f428",
            "32d1d7f5adc24638bbf9f9cb18fea712",
            "c85b0403e1a643559328325691cc52e0",
            "a812c56b53a74ad59650c9c766189826",
            "cc385a393ea14802bafdbd7da010c31d",
            "0808ba11a5e74b0882b2bab39871f549",
            "bc6b98b3473f4cb49455be0ef0dda8a1",
            "1c6c6470fb164e0bb8aa7b5a1dadebd1",
            "f9b2d33a901b408c9ac81238da952f76",
            "a32999de2a4b445b8b62c4671af42619",
            "116de93cb712445cab5eb6362dc94c7e",
            "a12f7026702b44f0bd0e636055f8e53a",
            "4180e04fb2b740b3b81d4e25360ff893",
            "2b2cd2056706408bae694e9cc2b08ac3",
            "76fd4a89ed024c56849829d9684dd8d8",
            "cf467985034b4fefb92b5d9d9867f022",
            "c71c86972f914464b2dc078db959f781",
            "e8c3d14869e142fab3b4989e6389c68e",
            "f770b05f05ad4c219cff457e57d90fda",
            "1e26f685b9834aed9e5e6a415cf64e35",
            "6baf63a2a6244322badd78644730cb66",
            "4c3f9576db5e4da1ba748ece13ab487a",
            "49416de57ac84d80b4b480c784285c39",
            "ada4f5fbf8ed447e90301df539e9398f",
            "1ea459bc0974456eb3cda2c673a55e86"
          ]
        },
        "id": "YFSG88v_1X_4",
        "outputId": "f051d724-9b35-4ade-bcbb-9ee489e94560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9621e98a947f493bb5f9261b6729f29f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab545785f2754e9094c0bc929da964b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a812c56b53a74ad59650c9c766189826"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/2.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76fd4a89ed024c56849829d9684dd8d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'eval'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate text description with the model and save it to a list\n",
        "\n"
      ],
      "metadata": {
        "id": "gbJPPKnv8zgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames_dir = location.replace('.mp4', '') + \"-opencv\"\n",
        "fields = [\"Title\", \"Cap1\", \"Cap2\", \"Cap3\"]\n",
        "rows = []\n",
        "for rawImg in os.listdir(frames_dir):\n",
        "  procRaw = Image.open(frames_dir + \"/\" + rawImg).convert(\"RGB\")\n",
        "  image = vis_processors[\"eval\"](procRaw).unsqueeze(0).to(device)\n",
        "  rows.append([rawImg] + model.generate({\"image\": image}, use_nucleus_sampling=True, num_captions=3))"
      ],
      "metadata": {
        "id": "72GflAS38xw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "5e698551-02cf-45b0-9a7e-6711ef9f2d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3feaef57fd37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprocRaw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrawImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvis_processors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocRaw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrawImg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_nucleus_sampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_captions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/blip_models/blip_caption.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, samples, use_nucleus_sampling, num_beams, max_length, min_length, top_p, repetition_penalty, num_captions)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# get decoded text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         decoder_out = self.text_decoder.generate_from_encoder(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mtokenized_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mvisual_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mgenerate_from_encoder\u001b[0;34m(self, tokenized_prompt, visual_embeds, sep_token_id, pad_token_id, use_nucleus_sampling, num_beams, max_length, min_length, top_p, repetition_penalty, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_nucleus_sampling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;31m# nucleus sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m             outputs = self.generate(\n\u001b[0m\u001b[1;32m   1347\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1438\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2443\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2444\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, return_logits, is_decoder, reduction, mode, soft_labels, alpha)\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1211\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, is_decoder, mode)\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, mode)\u001b[0m\n\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    593\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, mode)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         )\n\u001b[0;32m--> 437\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     ):\n\u001b[0;32m--> 346\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/lavis/models/med.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the rows with respect to the frames\n",
        "\n"
      ],
      "metadata": {
        "id": "_G1Orhlh81yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(rows, key=lambda x: x[0], reverse=False)"
      ],
      "metadata": {
        "id": "niY7B0vO84ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cff767a-5544-47a3-e28a-596e0822061f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['frame0-00-00.00.jpg',\n",
              "  'a man holding up his arms as if to lift a tennis ball with one hand',\n",
              "  'two elephants walking down the street, as people wait in line',\n",
              "  'there is a light that is shining in the dark'],\n",
              " ['frame0-00-00.17.jpg',\n",
              "  'a picture taken of an airplane at night',\n",
              "  'a cat laying down on a window sill',\n",
              "  'two white flowers with dark background'],\n",
              " ['frame0-00-00.33.jpg',\n",
              "  'the black space in front of the cat is very dark',\n",
              "  'an empty toilet with a small sink and large mirror',\n",
              "  'an elephant with large horns and long mane standing in the dark'],\n",
              " ['frame0-00-00.50.jpg',\n",
              "  'black and white photo of an intersection at night',\n",
              "  'this is a photo taken of a building with some dark buildings',\n",
              "  'a couple of tall buildings that have dark walls in the background'],\n",
              " ['frame0-00-00.67.jpg',\n",
              "  'the large brown building has a clock on it',\n",
              "  'the view of the top of several buildings and trees from a distance',\n",
              "  'city in the dark with skyscrapers and a man on top'],\n",
              " ['frame0-00-00.83.jpg',\n",
              "  'this is an image of a city skyline with dark buildings',\n",
              "  'a full view of a city at night',\n",
              "  'dark city street filled with trees and high rise buildings'],\n",
              " ['frame0-00-01.00.jpg',\n",
              "  'there is a building that is next to other buildings',\n",
              "  'a black and white photo of tall buildings',\n",
              "  'the cityscape is full of very dark brown buildings'],\n",
              " ['frame0-00-01.17.jpg',\n",
              "  'two buildings with a plane flying in the sky',\n",
              "  'two red trains are passing in front of some tall buildings',\n",
              "  'a large group of tall buildings towering above the city'],\n",
              " ['frame0-00-01.33.jpg',\n",
              "  'there is a blurry image of a city with a lot of buildings',\n",
              "  'a view of buildings and the tops of trees',\n",
              "  'there are several high rise buildings and some cars in the road'],\n",
              " ['frame0-00-01.50.jpg',\n",
              "  'a group of buildings that have some windows',\n",
              "  'several city buildings with cars driving down a busy street',\n",
              "  'very tall brick building in the background with cars parked nearby'],\n",
              " ['frame0-00-01.67.jpg',\n",
              "  'many very tall buildings in the city',\n",
              "  'an airplane flying in the air next to buildings',\n",
              "  'some buildings and a train in the distance'],\n",
              " ['frame0-00-01.84.jpg',\n",
              "  'a tall city is shown with a white frisbee in the foreground',\n",
              "  'some very tall buildings in a city',\n",
              "  'a bunch of buildings and a cloudy sky'],\n",
              " ['frame0-00-02.00.jpg',\n",
              "  'the building is tall and the signs are red',\n",
              "  'many tall buildings near one another in a city',\n",
              "  'the big city with a lot of tall buildings is very dirty'],\n",
              " ['frame0-00-02.17.jpg',\n",
              "  'city skyline with several tall buildings in the foreground',\n",
              "  'view of skyscrapers of an area with cars driving past them',\n",
              "  'view of city buildings in the distance, from a bus'],\n",
              " ['frame0-00-02.34.jpg',\n",
              "  'tall brown buildings along the highway with traffic',\n",
              "  'very tall buildings along a body of water',\n",
              "  'some tall buildings stand in front of the sky'],\n",
              " ['frame0-00-02.50.jpg',\n",
              "  'two large brown buildings are in the distance and a street sign is out front of them',\n",
              "  'two buildings sitting in a big city park',\n",
              "  'several high rise buildings in the city with street signs'],\n",
              " ['frame0-00-02.67.jpg',\n",
              "  'a tooth brush in front of a blurry picture',\n",
              "  'the man has a tie around his neck',\n",
              "  'a cat with its head turned backwards'],\n",
              " ['frame0-00-02.84.jpg',\n",
              "  'three brown brick buildings with windows on each side',\n",
              "  'two tall buildings are facing different directions, and a clock is posted in the foreground',\n",
              "  'two tall brown buildings in the background and a blue street sign'],\n",
              " ['frame0-00-03.00.jpg',\n",
              "  'several buildings in the city with no people',\n",
              "  'there is no image on this page to describe',\n",
              "  'large buildings in the city with tall windows'],\n",
              " ['frame0-00-03.17.jpg',\n",
              "  'many tall buildings next to each other on a clear day',\n",
              "  'several high rise buildings in an urban setting',\n",
              "  'view from a building window of a city with tall buildings'],\n",
              " ['frame0-00-03.34.jpg',\n",
              "  'a few tall brown buildings and cars in the road',\n",
              "  'tall brick buildings in a large city with green leaves',\n",
              "  'several tall brick buildings with the tops of skyscrapers'],\n",
              " ['frame0-00-03.50.jpg',\n",
              "  'tall buildings are sitting near each other',\n",
              "  'a city street has many buildings with tall brown buildings',\n",
              "  'the building in the city is next to another skyscraper'],\n",
              " ['frame0-00-03.67.jpg',\n",
              "  'two tall buildings with a train passing in front',\n",
              "  'tall brick buildings sitting in the city skyline',\n",
              "  'two tall brown building next to each other'],\n",
              " ['frame0-00-03.84.jpg',\n",
              "  'there are many brown buildings with a tall white building',\n",
              "  'there are three buildings on the left with windows at each',\n",
              "  'view of a large city and a park'],\n",
              " ['frame0-00-04.00.jpg',\n",
              "  'some very tall brown buildings with many windows',\n",
              "  'several large buildings are visible behind a body of water',\n",
              "  'many buildings in a large city with cars parked'],\n",
              " ['frame0-00-04.17.jpg',\n",
              "  'the skyscrapers in a city are near each other',\n",
              "  'the view from far away shows tall buildings and green street lights',\n",
              "  'a car parked outside of large buildings in the city'],\n",
              " ['frame0-00-04.34.jpg',\n",
              "  'a lot of large brown buildings with no windows',\n",
              "  'a couple of large brown buildings sitting in the middle of a city',\n",
              "  'two very large brown buildings in the city'],\n",
              " ['frame0-00-04.50.jpg',\n",
              "  'there is no image here to provide a caption for',\n",
              "  'a few tall brown buildings with windows and no doors',\n",
              "  'a very large brown building surrounded by tall buildings'],\n",
              " ['frame0-00-04.67.jpg',\n",
              "  'several large brick buildings against a blue sky',\n",
              "  'a parking meter that is next to several tall buildings',\n",
              "  'the tall brick buildings are visible from the street'],\n",
              " ['frame0-00-04.84.jpg',\n",
              "  'the sky scrapes past the tall buildings in the city',\n",
              "  'a couple of tall brown buildings next to each other',\n",
              "  'a tall building with a parking meter and some cars parked in front of it'],\n",
              " ['frame0-00-05.00.jpg',\n",
              "  'the little girl is sitting in the subway',\n",
              "  'the little girl is sitting on the train',\n",
              "  'the little girl sits alone on the train'],\n",
              " ['frame0-00-05.17.jpg',\n",
              "  'the young girl is sitting down in the seat of the subway train',\n",
              "  'a little girl is sitting on the train',\n",
              "  'a little girl standing on a subway car'],\n",
              " ['frame0-00-05.34.jpg',\n",
              "  'young girl on the train with her arms crossed',\n",
              "  'the little girl is sitting on the subway',\n",
              "  'a small child wearing a coat is on a train'],\n",
              " ['frame0-00-05.51.jpg',\n",
              "  'a young girl is waiting on the subway for her train',\n",
              "  'a little kid is looking at something while riding the subway',\n",
              "  'the small child is sitting on the subway'],\n",
              " ['frame0-00-05.67.jpg',\n",
              "  'young asian girl in jacket on subway',\n",
              "  'an asian girl looks bored while sitting on the train',\n",
              "  'young child sitting alone on a commuter train'],\n",
              " ['frame0-00-05.84.jpg',\n",
              "  'the little girl is sitting down with her arms folded up',\n",
              "  'a little girl sitting on a public transportation seat',\n",
              "  'a small kid wearing a winter coat sits on a train'],\n",
              " ['frame0-00-06.01.jpg',\n",
              "  'little girl sitting on a train looking at something',\n",
              "  'a little girl is sitting on the bus',\n",
              "  'the little girl is sitting on the train'],\n",
              " ['frame0-00-06.17.jpg',\n",
              "  'a little girl that is sitting down on a bus',\n",
              "  'a young girl wearing a yellow puffy coat sitting down',\n",
              "  'a little girl sitting in a seat of a subway train'],\n",
              " ['frame0-00-06.34.jpg',\n",
              "  'an asian girl sitting down on a train looking to her left',\n",
              "  'little girl sitting on the subway looking at the camera',\n",
              "  'the little child is sitting in the seat of a train'],\n",
              " ['frame0-00-06.51.jpg',\n",
              "  'an image of a little girl with brown clothes',\n",
              "  'a small kid sitting on a bus and looking at the camera',\n",
              "  'a young asian girl sitting on a bus'],\n",
              " ['frame0-00-06.67.jpg',\n",
              "  'a little girl dressed in gold sits on a subway',\n",
              "  'a little girl is waiting for her train to arrive',\n",
              "  'a small girl sitting in a public bus'],\n",
              " ['frame0-00-06.84.jpg',\n",
              "  'little girl sitting on the subway looking out the window',\n",
              "  'young asian girl sitting in bus on winter day',\n",
              "  'there is a little girl in a coat sitting on the bus'],\n",
              " ['frame0-00-07.01.jpg',\n",
              "  'a small child with long dark hair sitting on a subway',\n",
              "  'a girl with her arms folded sitting down on a bus',\n",
              "  'a child wearing a jacket is sitting on the bus'],\n",
              " ['frame0-00-07.17.jpg',\n",
              "  'a young girl in a tan coat is sitting on a train',\n",
              "  'the child is wearing a warm coat on the subway',\n",
              "  'a young girl dressed in brown is looking up at someone'],\n",
              " ['frame0-00-07.34.jpg',\n",
              "  'a person with a hat sitting on steps with sticks',\n",
              "  'a man is holding two swords on the sidewalk',\n",
              "  'an older man is sitting on a step holding two sword like objects'],\n",
              " ['frame0-00-07.51.jpg',\n",
              "  'a man holding a sword next to a bag',\n",
              "  'the man is sitting on a bench with his sword',\n",
              "  'there is a man sitting with some swords on the street'],\n",
              " ['frame0-00-07.67.jpg',\n",
              "  'a man is sitting down and holding two swords',\n",
              "  'man sitting on the ground with two swords',\n",
              "  'a person sits on the ground with two swords in their hands'],\n",
              " ['frame0-00-07.84.jpg',\n",
              "  'a man sitting on the ground with two swords in hand',\n",
              "  'man in plaid pants is sitting on the ground using an umbrella',\n",
              "  'a man sitting down with his guitar string in hand'],\n",
              " ['frame0-00-08.01.jpg',\n",
              "  'a man sitting on the side of a building and playing a game',\n",
              "  'a man in the street holding a cane and wearing a woolly cap',\n",
              "  'an elderly man sitting down with a knitting machine'],\n",
              " ['frame0-00-08.17.jpg',\n",
              "  'there is a man sitting on the ground with weapons',\n",
              "  'an old man sitting down with a sword',\n",
              "  'a man holding two large swords sitting on the side walk'],\n",
              " ['frame0-00-08.34.jpg',\n",
              "  'a man sitting down next to a woman holding an umbrella',\n",
              "  'a man is sitting on the ground holding two swords',\n",
              "  'a man holding an instrument while sitting on a street'],\n",
              " ['frame0-00-08.51.jpg',\n",
              "  'a person is sitting on the steps with a cane',\n",
              "  'a person sitting on some steps with a stick',\n",
              "  'a man on the street holding a walking stick'],\n",
              " ['frame0-00-08.68.jpg',\n",
              "  'a man sits on the side of a stair railing, writing on his cell phone',\n",
              "  'a man sitting outside with an odd looking bag',\n",
              "  'an older man holding something in his hands while standing near the railing'],\n",
              " ['frame0-00-08.84.jpg',\n",
              "  'a man with a umbrella on his hand near a fence',\n",
              "  'a man with a bag and two sword standing on the street',\n",
              "  'an older man holding a stick and walking down a street'],\n",
              " ['frame0-00-09.01.jpg',\n",
              "  'a man is standing next to a gate eating something',\n",
              "  'a man in a hat leaning over bars while eating',\n",
              "  'the man is holding his cell phone and leaning up against a gate'],\n",
              " ['frame0-00-09.18.jpg',\n",
              "  'a woman carrying a white teddy bear through a gate',\n",
              "  'a little boy looking at his phone near a fence',\n",
              "  'a couple of kids are sitting on the steps'],\n",
              " ['frame0-00-09.34.jpg',\n",
              "  'a brick wall next to a metal gate and metal fence',\n",
              "  'an image of a sign for a street parking garage',\n",
              "  'a metal gate near a sign that says street'],\n",
              " ['frame0-00-09.51.jpg',\n",
              "  'there is a street sign on the side of the building',\n",
              "  'a sign on the side of a building that says canal street',\n",
              "  'there is a sign on the outside of a store'],\n",
              " ['frame0-00-09.68.jpg',\n",
              "  'a black sign that reads canal street on it',\n",
              "  'a street sign is hanging on the side of a building',\n",
              "  'a sign on a wall near a doorway'],\n",
              " ['frame0-00-09.84.jpg',\n",
              "  'a sign that is on a white building',\n",
              "  'an image of a street sign on a wall',\n",
              "  'the sign on the wall says canal street'],\n",
              " ['frame0-00-10.01.jpg',\n",
              "  'there is a small sign that says canal street',\n",
              "  'an entrance to the canal street subway station',\n",
              "  'an outside of a subway station in the uk'],\n",
              " ['frame0-00-10.18.jpg',\n",
              "  'a white building with a black sign on it',\n",
              "  'a black and white sign is in front of some building',\n",
              "  'a sign is shown on a building near a fence'],\n",
              " ['frame0-00-10.34.jpg',\n",
              "  'sign for canal street attached to white brick building',\n",
              "  'a black and white sign on the side of a wall',\n",
              "  'street sign posted on white brick wall in urban area'],\n",
              " ['frame0-00-10.51.jpg',\n",
              "  'the map is marked with an arrow pointing out into hell',\n",
              "  'a red circular arrow on the city map of the region',\n",
              "  'a map with the center of an arrow pointing down'],\n",
              " ['frame0-00-10.68.jpg',\n",
              "  'a photo of the map in red with an arrow pointing to it',\n",
              "  'a red circle pointing towards the right direction',\n",
              "  'the red circle is across a map, in red'],\n",
              " ['frame0-00-10.84.jpg',\n",
              "  'there is a street map with a red circle in the middle',\n",
              "  'a map showing the location of a canadian church',\n",
              "  'there is a map that has some words on it'],\n",
              " ['frame0-00-11.01.jpg',\n",
              "  'a map with an image of the street marked in red',\n",
              "  'a map with a red circle that says canal st and a picture of a church in the bottom right corner',\n",
              "  'a map of an area with a street sign that says canal st'],\n",
              " ['frame0-00-11.18.jpg',\n",
              "  'the word that is circled over the map is clearly red',\n",
              "  'the red arrow points to an arrow in a map',\n",
              "  'a map with a red circle in the middle'],\n",
              " ['frame0-00-11.34.jpg',\n",
              "  'a red circle is in the middle of a map',\n",
              "  'an area with red markers indicating the location of canals at canal street',\n",
              "  'a map with a circle with a cross in it'],\n",
              " ['frame0-00-11.51.jpg',\n",
              "  'a map with a red circle that says you are here',\n",
              "  'the circle is red over a street map',\n",
              "  'a map with a sign and arrow in it'],\n",
              " ['frame0-00-11.68.jpg',\n",
              "  'a map with a pin and a circle with a red arrows',\n",
              "  'a red cross is on top of the map',\n",
              "  'a map with a red circle and some text on it'],\n",
              " ['frame0-00-11.85.jpg',\n",
              "  'a map with the location of a red circle and you are here here in the middle',\n",
              "  'a street map with a red circle circled in it',\n",
              "  'a city map with a red circle and you are here sign'],\n",
              " ['frame0-00-12.01.jpg',\n",
              "  'a map with a circle in it and a small red sign',\n",
              "  'a map has a red arrow in it',\n",
              "  'map that shows where there is a candle stick'],\n",
              " ['frame0-00-12.18.jpg',\n",
              "  'a close up image of a street map with a no u - turn arrow on it',\n",
              "  'a street map with no name in the middle',\n",
              "  'the map of what it is all about'],\n",
              " ['frame0-00-12.35.jpg',\n",
              "  'a red circle around a street sign that says you are here',\n",
              "  'a map that has the red circle and you are here',\n",
              "  'a map with a cross in it and you are here on the left'],\n",
              " ['frame0-00-12.51.jpg',\n",
              "  'several people standing around near one another with their feet up',\n",
              "  'people are lined up in different sizes and shapes',\n",
              "  'the group of legs are standing on the ground'],\n",
              " ['frame0-00-12.68.jpg',\n",
              "  'the group of people are standing next to each other',\n",
              "  'feet in jeans and sandals are standing on the sidewalk',\n",
              "  'the bottom half of people standing together wearing different colored shoes'],\n",
              " ['frame0-00-12.85.jpg',\n",
              "  'several feet standing around in different positions next to each other',\n",
              "  'some very cool looking shoes by some people',\n",
              "  'this is a group of people standing close together'],\n",
              " ['frame0-00-13.01.jpg',\n",
              "  'there are people standing behind a person standing in the middle',\n",
              "  'a group of people standing around each other on a floor',\n",
              "  'some people standing with shoes on and looking down'],\n",
              " ['frame0-00-13.18.jpg',\n",
              "  'several people standing in line and one is wearing some tennis shoes',\n",
              "  'the bottom half of people standing behind them with shoes',\n",
              "  'the feet of several people standing together on a floor'],\n",
              " ['frame0-00-13.35.jpg',\n",
              "  'several people standing next to each other with jeans',\n",
              "  'there are a lot of people standing in a row',\n",
              "  \"a small group of people's feet with their shoes on\"],\n",
              " ['frame0-00-13.51.jpg',\n",
              "  'a group of people wearing boots standing next to each other',\n",
              "  'this photo shows a lot of people standing next to each other',\n",
              "  'a group of feet standing next to each other'],\n",
              " ['frame0-00-13.68.jpg',\n",
              "  'a picture of someones shoes and shoes sitting on the ground',\n",
              "  \"a blurry photo of someone's legs in boots\",\n",
              "  'blurry photo of a pair of tall boots'],\n",
              " ['frame0-00-13.85.jpg',\n",
              "  'people wearing boots standing on a sidewalk in a line',\n",
              "  'a group of people standing on top of a floor next to one another',\n",
              "  'a group of people walking on the street with one person in front'],\n",
              " ['frame0-00-14.01.jpg',\n",
              "  'the legs of several people standing by a ball of fruit',\n",
              "  'people on the sidewalk with a small toy on the ground',\n",
              "  'some people with shoes that are standing in front of something'],\n",
              " ['frame0-00-14.18.jpg',\n",
              "  'two legs wearing shoes are in front of people',\n",
              "  'a person standing on top of a white shoe',\n",
              "  'a close up of a person walking while wearing white sneakers'],\n",
              " ['frame0-00-14.35.jpg',\n",
              "  'a pair of feet are shown on the ground',\n",
              "  'shoes with colorful trims and a dog on the floor',\n",
              "  'the feet and ankles of a man in grey sneakers'],\n",
              " ['frame0-00-14.51.jpg',\n",
              "  'a person standing with a bag on their side',\n",
              "  'someone standing next to a bag and shoes',\n",
              "  \"a person's feet in sneakers and pants\"],\n",
              " ['frame0-00-14.68.jpg',\n",
              "  \"a person's feet and shoes with scattered confetti on the ground\",\n",
              "  'several people are walking and confetti is flying',\n",
              "  'a man is walking with his shoes on'],\n",
              " ['frame0-00-14.85.jpg',\n",
              "  \"close up of a person's foot standing on a carpet of confetti\",\n",
              "  'people in blue jeans stand on a city sidewalk',\n",
              "  'a group of people standing around a floor with confetti'],\n",
              " ['frame0-00-15.02.jpg',\n",
              "  'someone standing with their feet up against a wall',\n",
              "  'the foot and boot on someones feet as they stand',\n",
              "  'people walking down the street in black boots'],\n",
              " ['frame0-00-15.18.jpg',\n",
              "  'a group of people standing near each other with confetti on the ground',\n",
              "  'three people walking and confetti scattered all around them',\n",
              "  'a group of people with boots and confetti on the floor'],\n",
              " ['frame0-00-15.35.jpg',\n",
              "  \"close up of several people's legs and feet in the street\",\n",
              "  'a group of men standing with their shoes',\n",
              "  'there are several people standing next to each other'],\n",
              " ['frame0-00-15.52.jpg',\n",
              "  'the people are standing with their legs apart on the ground',\n",
              "  'these feet are on top of some garbage near a pair of jeans',\n",
              "  'a bunch of people with footwear on standing next to each other'],\n",
              " ['frame0-00-15.68.jpg',\n",
              "  'some people feet on a carpet and people in chairs',\n",
              "  \"the bottom part of someone's feet on a sidewalk with confetti on the ground\",\n",
              "  'several people standing close to each other'],\n",
              " ['frame0-00-15.85.jpg',\n",
              "  'a bunch of people on their feet walking around with confetti scattered around them',\n",
              "  'there are many people walking down the street on skates',\n",
              "  \"this is someone's feet standing in front of a group of people\"],\n",
              " ['frame0-00-16.02.jpg',\n",
              "  'the legs of some people who are standing in front of a building',\n",
              "  'people standing next to each other in front of people',\n",
              "  'feet in black and red with colored writing on the ground'],\n",
              " ['frame0-00-16.18.jpg',\n",
              "  'this is a blurry picture of many people walking',\n",
              "  'an blurry view of people in the crowd at a street market',\n",
              "  'many people and a street in a blurred image'],\n",
              " ['frame0-00-16.35.jpg',\n",
              "  'many people are walking down a street crowded with shoppers',\n",
              "  'an image of some people in the street',\n",
              "  'a large group of people standing around a street'],\n",
              " ['frame0-00-16.52.jpg',\n",
              "  'a crowd of people are standing in front of the parade',\n",
              "  'the crowd is watching a man on a skateboard',\n",
              "  'crowd of people gathered in city area during daytime'],\n",
              " ['frame0-00-16.68.jpg',\n",
              "  'people gathered along a sidewalk in an area full of people',\n",
              "  'crowd of people standing in front of a group of men',\n",
              "  'crowd of people standing on the street in front of spectators'],\n",
              " ['frame0-00-16.85.jpg',\n",
              "  'there are a lot of people in the street',\n",
              "  'a crowd watches people in the street with cameras',\n",
              "  'two men standing on the side of a road as people stand nearby'],\n",
              " ['frame0-00-17.02.jpg',\n",
              "  'a crowd of people standing on a street',\n",
              "  'many people are walking in the street by a building',\n",
              "  'a group of people standing on the side of a road in a crowd'],\n",
              " ['frame0-00-17.18.jpg',\n",
              "  'people standing on the sidewalk in front of a crowd',\n",
              "  'several people lined up to watch as they walk',\n",
              "  'a group of people stand in a line along a crowded street'],\n",
              " ['frame0-00-17.35.jpg',\n",
              "  'the crowds are standing on the street watching a parade',\n",
              "  'several people are walking down a crowded street',\n",
              "  'people standing outside while crowds watch as they walk on the street'],\n",
              " ['frame0-00-17.52.jpg',\n",
              "  'a crowd of people on a city street',\n",
              "  'a crowded street with a group of people',\n",
              "  'a group of people standing on the side of a street'],\n",
              " ['frame0-00-17.68.jpg',\n",
              "  'people gathered together to watch an outside concert',\n",
              "  'several people walking down a street in a group',\n",
              "  'a bunch of people stand around as a man looks at them'],\n",
              " ['frame0-00-17.85.jpg',\n",
              "  'people on a busy street in front of buildings',\n",
              "  'many people are standing on a street with metal bars',\n",
              "  'many people gathered outside in front of a building'],\n",
              " ['frame0-00-18.02.jpg',\n",
              "  'a crowd watches as people are on a street in an asian city',\n",
              "  'large group of people marching down street with buildings and shops',\n",
              "  'a group of people walking down a street'],\n",
              " ['frame0-00-18.18.jpg',\n",
              "  'there are a lot of people that are standing together',\n",
              "  'a crowded street with people on the sidewalk, as well as police officers and firefighters',\n",
              "  'a street scene with a lot of people'],\n",
              " ['frame0-00-18.35.jpg',\n",
              "  'people watching on street in asian country',\n",
              "  'there are many people gathered on the street together',\n",
              "  'this is a view of the crowd of people in china'],\n",
              " ['frame0-00-18.52.jpg',\n",
              "  'a group of people walking down a crowded street',\n",
              "  'a crowd of people watch as people are standing on the street',\n",
              "  'large crowd watching parade in a big city'],\n",
              " ['frame0-00-18.69.jpg',\n",
              "  'a large crowd of people waiting to greet and watch',\n",
              "  'the crowd is waiting to enter the parade',\n",
              "  'the crowd is standing in the street outside'],\n",
              " ['frame0-00-18.85.jpg',\n",
              "  'people are standing on the street during the celebrations',\n",
              "  'a large crowd of people on a city street',\n",
              "  'people stand in a line as they march down the street'],\n",
              " ['frame0-00-19.02.jpg',\n",
              "  'large group of people on a busy city street',\n",
              "  'a group of people on bikes in the street near a crowd',\n",
              "  'there are many people standing in a line on the sidewalk'],\n",
              " ['frame0-00-19.19.jpg',\n",
              "  'a large crowd of people standing on the side of a road',\n",
              "  'people standing around in line at a parade',\n",
              "  'a street that has several people on it with a lot of buildings in the background'],\n",
              " ['frame0-00-19.35.jpg',\n",
              "  'a number of people on a city street near a bunch of signs',\n",
              "  'the city street is crowded with people who are waiting to vote',\n",
              "  'large group of people standing on street in city'],\n",
              " ['frame0-00-19.52.jpg',\n",
              "  'a group of people stand on the side walk',\n",
              "  'a crowd is gathered around a crowded sidewalk',\n",
              "  'there are many people that are standing on the street'],\n",
              " ['frame0-00-19.69.jpg',\n",
              "  'a crowd in a crowded area watching people wearing helmets',\n",
              "  'a crowd of people standing on the side of a road',\n",
              "  'people crowd down the street as a man stands in the middle of a city street'],\n",
              " ['frame0-00-19.85.jpg',\n",
              "  'there are many people walking on the street',\n",
              "  'the crowd is gathered for a demonstration in the chinatown',\n",
              "  'a group of people on a street next to a fence'],\n",
              " ['frame0-00-20.02.jpg',\n",
              "  'a person standing behind a gate with a hat on',\n",
              "  'an elderly man and a woman behind bars at an alleyway gate',\n",
              "  'a couple of people are sitting outside behind bars'],\n",
              " ['frame0-00-20.19.jpg',\n",
              "  'a young person in a hat and coat leans out a gate',\n",
              "  'man in blue coat holding on to bars on gate',\n",
              "  'a man wearing blue jacket standing near metal bars'],\n",
              " ['frame0-00-20.35.jpg',\n",
              "  'a man in a hat behind bars in a fence',\n",
              "  'a jail cell that has a large man in the cell behind bars',\n",
              "  'a person holding a caged animal looking over an iron gate'],\n",
              " ['frame0-00-20.52.jpg',\n",
              "  'an image of person in jail looking into cage',\n",
              "  'man standing behind bars in the street behind a gate',\n",
              "  'a group of people standing near a metal gate'],\n",
              " ['frame0-00-20.69.jpg',\n",
              "  'a man looking over a gate and a person standing behind it',\n",
              "  'a man with a police cap, jacket, and backpack behind a metal fence',\n",
              "  'a man is standing behind bars in an jail cell'],\n",
              " ['frame0-00-20.85.jpg',\n",
              "  'a man is behind an iron gate with people sitting nearby',\n",
              "  'several people are in a large metal cage',\n",
              "  'a person behind the fence looking through and out'],\n",
              " ['frame0-00-21.02.jpg',\n",
              "  'several people standing behind metal bars in front of stone building',\n",
              "  'a man in police uniform is inside a fence',\n",
              "  'a man sitting on the side of a train looking through the gate'],\n",
              " ['frame0-00-21.19.jpg',\n",
              "  'a blue faced man peeking out behind a metal fence',\n",
              "  'a man holding onto an iron bars behind a fence',\n",
              "  'a man who is in jail and is not seen through the gates'],\n",
              " ['frame0-00-21.35.jpg',\n",
              "  'a man in a black cap leaning on a silver railing',\n",
              "  'an elephant is locked up to the fence',\n",
              "  'the person behind the gate is holding a cellphone'],\n",
              " ['frame0-00-21.52.jpg',\n",
              "  'some people are seen looking through bars',\n",
              "  'a man is leaning on a gate in a jail cell',\n",
              "  'a person that is holding onto a gate with a bunch of people'],\n",
              " ['frame0-00-21.69.jpg',\n",
              "  'two people are peering into the iron railing of an old brick building',\n",
              "  'a man in uniform is behind a gate while looking over',\n",
              "  'the man behind the bars is holding up his phone'],\n",
              " ['frame0-00-21.86.jpg',\n",
              "  'two people standing behind a gate with bars',\n",
              "  'a man is staring out from behind the gate',\n",
              "  'a man is behind a gate on a sidewalk'],\n",
              " ['frame0-00-22.02.jpg',\n",
              "  'this is the view of several people outside behind an iron fence',\n",
              "  'a pair of women standing at the top of a tall metal gate',\n",
              "  'a man in grey shirt standing next to a metal fence'],\n",
              " ['frame0-00-22.19.jpg',\n",
              "  'the man is hanging over the gates looking at his watch',\n",
              "  'several people behind iron bars on a building',\n",
              "  'a man leaning on the bars of a gate'],\n",
              " ['frame0-00-22.36.jpg',\n",
              "  'a guy leaning over an iron gate to look through it',\n",
              "  'a young man leaning against an iron fence',\n",
              "  'a man standing by a large iron fence'],\n",
              " ['frame0-00-22.52.jpg',\n",
              "  'the man looks through the bars on his balcony',\n",
              "  'a man standing next to a gate with a bunch of tools',\n",
              "  'a man with glasses stands on a gate'],\n",
              " ['frame0-00-22.69.jpg',\n",
              "  'a man and a woman are standing on a balcony',\n",
              "  'a man looking through the fence and making faces',\n",
              "  'a man holding a baseball bat standing at a fence'],\n",
              " ['frame0-00-22.86.jpg',\n",
              "  'a boy in a grey shirt looks over the fence at a woman',\n",
              "  'the man is standing near the metal fence with his hand on the gate',\n",
              "  'a man looking over an iron balcony rail'],\n",
              " ['frame0-00-23.02.jpg',\n",
              "  'a person that is sitting behind a gate',\n",
              "  'the young man is standing on a metal fence looking down',\n",
              "  'a man in a grey shirt and glasses standing behind bars'],\n",
              " ['frame0-00-23.19.jpg',\n",
              "  'a young man looks out from a balcony',\n",
              "  'two people standing in a building next to a metal gate',\n",
              "  'a boy standing on an iron fence looking over'],\n",
              " ['frame0-00-23.36.jpg',\n",
              "  'there is a young man standing on the balcony of a building',\n",
              "  'a young man is hanging out the balcony',\n",
              "  'a boy smoking a cigarette, standing behind metal bars'],\n",
              " ['frame0-00-23.52.jpg',\n",
              "  'a man is sitting on the balcony holding onto a railing',\n",
              "  'man looking out the iron railing on his balcony',\n",
              "  'a man looking out of an iron fence'],\n",
              " ['frame0-00-23.69.jpg',\n",
              "  'this is a picture of an urban street',\n",
              "  'a city street that is lined with buildings',\n",
              "  'an urban street with people and a fire truck'],\n",
              " ['frame0-00-23.86.jpg',\n",
              "  'a woman standing on a street looking at the camera',\n",
              "  'blurred image of woman looking out window in urban area',\n",
              "  \"an blurry photo of a woman's face\"],\n",
              " ['frame0-00-24.02.jpg',\n",
              "  'a blurry photo shows a woman walking down a street',\n",
              "  'blurry image of woman walking in a city',\n",
              "  'blurry image of woman walking down an urban street'],\n",
              " ['frame0-00-24.19.jpg',\n",
              "  'the large statue is shown on top of a building',\n",
              "  'there is a large clock on top of a tower',\n",
              "  'a busy city street with a clock tower on top'],\n",
              " ['frame0-00-24.36.jpg',\n",
              "  'people walking down a city street during the day',\n",
              "  'an urban view from the street looking at buildings',\n",
              "  'a crowd is walking along the sidewalk outside'],\n",
              " ['frame0-00-24.52.jpg',\n",
              "  'people walk on a busy city street in new york',\n",
              "  'large group of people are walking on a crowded street',\n",
              "  'people walking around in a crowded city with the tall building behind them'],\n",
              " ['frame0-00-24.69.jpg',\n",
              "  'crowds walking through a city on the sidewalk',\n",
              "  'some people standing on a busy street corner',\n",
              "  'this is a busy city street filled with people'],\n",
              " ['frame0-00-24.86.jpg',\n",
              "  'an image of people in the city going down the street',\n",
              "  'a group of people on a city street with signs and a sky scraper',\n",
              "  'the crowd is standing on the sidewalk in front of the tall buildings'],\n",
              " ['frame0-00-25.02.jpg',\n",
              "  'a crowd of people walking around on a busy city street',\n",
              "  'there is a large group of people walking in the street',\n",
              "  'blurry image of a crowded street with pedestrians'],\n",
              " ['frame0-00-25.19.jpg',\n",
              "  'woman with dreads walking around on a crowded city street',\n",
              "  'an excited woman smiling in a crowded city',\n",
              "  'woman looking at camera while wearing scarf on city street'],\n",
              " ['frame0-00-25.36.jpg',\n",
              "  'a woman wearing a scarf talks on a cell phone',\n",
              "  'a woman laughing while standing in a crowded street',\n",
              "  'a woman looking up in the air and laughing'],\n",
              " ['frame0-00-25.53.jpg',\n",
              "  'this is a picture of a man in front of a crowd',\n",
              "  'an asian man in black and purple is on his cell phone',\n",
              "  'a crowd of people walking down a street'],\n",
              " ['frame0-00-25.69.jpg',\n",
              "  'a crowd in a crowded city street with a woman standing at the back of her head',\n",
              "  'the people are standing on the side walk',\n",
              "  'this is an image of a woman talking to people'],\n",
              " ['frame0-00-25.86.jpg',\n",
              "  'a girl stands with two other young girls on a crowded street',\n",
              "  'a little girl standing between other children talking',\n",
              "  'this girl is holding onto another woman while standing outside'],\n",
              " ['frame0-00-26.03.jpg',\n",
              "  'a group of girls standing in the middle of a street',\n",
              "  'a group of girls are standing in a crowded street',\n",
              "  'a group of children standing around and talking in the street'],\n",
              " ['frame0-00-26.19.jpg',\n",
              "  'three girls stand near each other in a street',\n",
              "  'a group of people standing around one another in a city',\n",
              "  'there are two young girls standing in front of a group of people'],\n",
              " ['frame0-00-26.36.jpg',\n",
              "  'an image of two girls standing outside one has a small piece of paper in her hand',\n",
              "  'an image of two girls that are talking',\n",
              "  'a group of children with cell phones around their neck'],\n",
              " ['frame0-00-26.53.jpg',\n",
              "  'three children are standing in a crowded area',\n",
              "  'a girl is watching another kid play a game',\n",
              "  'there is a girl holding a cell phone and standing in the street'],\n",
              " ['frame0-00-26.69.jpg',\n",
              "  'an older girl standing next to a younger girl',\n",
              "  'a young girl walking down the street with other girls',\n",
              "  'two girls stand on a city street with people'],\n",
              " ['frame0-00-26.86.jpg',\n",
              "  'girl in blue coat looking at a red square with words on it',\n",
              "  'the young girl is in the city talking to someone',\n",
              "  'a young girl is holding a red object'],\n",
              " ['frame0-00-27.03.jpg',\n",
              "  'young girl holding an envelope in city street',\n",
              "  'a girl in a blue jacket holding up a piece of paper',\n",
              "  'a young girl holds up a red piece of paper'],\n",
              " ['frame0-00-27.19.jpg',\n",
              "  'a girl wearing a blue jacket and looking up',\n",
              "  'a woman wearing a blue jacket standing on a city street',\n",
              "  'girl talking on cell phone standing in street'],\n",
              " ['frame0-00-27.36.jpg',\n",
              "  'a woman in blue jacket walking on sidewalk next to woman',\n",
              "  'two girls on a city street holding a paper',\n",
              "  'the young woman is holding a piece of red paper'],\n",
              " ['frame0-00-27.53.jpg',\n",
              "  'two girls standing outside looking at something',\n",
              "  'a woman on a city street talks to children',\n",
              "  'two girls talking in a crowded street with no cars'],\n",
              " ['frame0-00-27.69.jpg',\n",
              "  'a group of girls standing in the street',\n",
              "  'a girl wearing a blue jacket is holding onto a red sign',\n",
              "  'a girl holding a small red card is on the street'],\n",
              " ['frame0-00-27.86.jpg',\n",
              "  'two little girls are standing in front of a building',\n",
              "  'three young girls stand on the side of a road near tall buildings',\n",
              "  'a girl holds up a sign with another girl on the back of a vehicle'],\n",
              " ['frame0-00-28.03.jpg',\n",
              "  'an image of a girl holding up a card',\n",
              "  'two girls are standing in the street while holding signs',\n",
              "  'an image of two girls standing outside in the city'],\n",
              " ['frame0-00-28.19.jpg',\n",
              "  'two young girls holding red blocks on the street',\n",
              "  'two little girls looking up at the sky with a red card',\n",
              "  'two young girls on a crowded city street'],\n",
              " ['frame0-00-28.36.jpg',\n",
              "  'young kids holding signs and pointing in a direction',\n",
              "  'a girl standing next to a child on the street',\n",
              "  'two young girls stand next to each other on the street'],\n",
              " ['frame0-00-28.53.jpg',\n",
              "  'the young girls on the street are all talking',\n",
              "  'a boy and a girl are standing next to each other',\n",
              "  'two little girls standing next to each other on the side of a building'],\n",
              " ['frame0-00-28.70.jpg',\n",
              "  'young girl handing out the letter to her friend',\n",
              "  'an image of two children holding an item up for auction',\n",
              "  'a woman in the street standing next to a young woman holding a red piece'],\n",
              " ['frame0-00-28.86.jpg',\n",
              "  'people are standing in front of a stage with bright colorful hats',\n",
              "  'a person in costume, and holding up their arms while people watch from behind',\n",
              "  'a parade with two clowns with a large group of spectators watching'],\n",
              " ['frame0-00-29.03.jpg',\n",
              "  'a man in a costume and hat standing in front of a crowd',\n",
              "  'some people and many other people are standing and watching',\n",
              "  'several people in headdresses and many holding flags in front of a crowd'],\n",
              " ['frame0-00-29.20.jpg',\n",
              "  'two people dressed in elaborate costumes perform',\n",
              "  'a parade that has people in traditional costumes',\n",
              "  'two groups of men in costume standing next to each other'],\n",
              " ['frame0-00-29.36.jpg',\n",
              "  'a crowd of people watching and watching something',\n",
              "  'a crowd at a parade in a city',\n",
              "  'people watch a parade as the firemen fire out a building'],\n",
              " ['frame0-00-29.53.jpg',\n",
              "  'a crowd of people with colorful outfits standing next to each other',\n",
              "  'crowd of people standing next to metal barricades watching',\n",
              "  'a man in black shirt and clown costume with crowd watching'],\n",
              " ['frame0-00-29.70.jpg',\n",
              "  'a crowd in a crowded area with people in costume',\n",
              "  'group of people standing in front of a crowd on the street',\n",
              "  'the group is watching the parade go by in the city'],\n",
              " ['frame0-00-29.86.jpg',\n",
              "  'large crowd watching a parade go by from outside',\n",
              "  'a bunch of people in costume at a parade',\n",
              "  'a crowd of people standing next to each other on a street'],\n",
              " ['frame0-00-30.03.jpg',\n",
              "  'a crowd of people walking down a street',\n",
              "  'two guys in bright colored suits, and people wearing red, yellow and blue',\n",
              "  'the crowd is standing next to the fence watching a person doing something'],\n",
              " ['frame0-00-30.20.jpg',\n",
              "  'several people are dressed in brightly colored outfits and one is holding an umbrella',\n",
              "  'people are watching people dressed in bright costumes',\n",
              "  'people dancing with umbrellas as an audience looks on'],\n",
              " ['frame0-00-30.36.jpg',\n",
              "  'people dancing at festival and holding umbrellas in air',\n",
              "  'a parade with people in costumes and wearing umbrellas',\n",
              "  'a group of people standing around each other holding umbrellas'],\n",
              " ['frame0-00-30.53.jpg',\n",
              "  'the crowd is gathered outside to watch the parade',\n",
              "  'a man is standing with an umbrella in front of a large crowd of people',\n",
              "  'group of people gathered together outside during parade'],\n",
              " ['frame0-00-30.70.jpg',\n",
              "  'a woman is holding an umbrella in the street',\n",
              "  'people dressed in bright colored clothes stand under an umbrella',\n",
              "  'a crowd is standing outside in the street'],\n",
              " ['frame0-00-30.86.jpg',\n",
              "  'a person wearing purple is walking down a street',\n",
              "  'people watching a parade from a crowded sidewalk',\n",
              "  'a man dressed in purple holds an umbrella in front of the crowd'],\n",
              " ['frame0-00-31.03.jpg',\n",
              "  'a person holding up a kite in front of an audience',\n",
              "  'there are many people on the street in the parade',\n",
              "  'the crowd is watching a parade in a city'],\n",
              " ['frame0-00-31.20.jpg',\n",
              "  'a parade has people dressed in costume as it passes by',\n",
              "  'many people gathered on the street with various items',\n",
              "  'a group of people in costume are holding umbrellas'],\n",
              " ['frame0-00-31.36.jpg',\n",
              "  'some people are playing on the street outside of a bank',\n",
              "  'people wearing red and yellow are watching some sort of parade',\n",
              "  'a crowd that is standing on a street'],\n",
              " ['frame0-00-31.53.jpg',\n",
              "  'a large group of people with colorful outfits walking around a city',\n",
              "  'a crowd of people on a street with parade floats',\n",
              "  'an image of people that are at the carnival'],\n",
              " ['frame0-00-31.70.jpg',\n",
              "  'a group of people in front of a building',\n",
              "  'an outdoor gathering for people and floats, in the city',\n",
              "  'people gathered and walking in the street at a carnival'],\n",
              " ['frame0-00-31.87.jpg',\n",
              "  'a bunch of people in costumes are watching a parade',\n",
              "  'a large group of people with some blue balloons',\n",
              "  'people standing in line waiting to enter a bank'],\n",
              " ['frame0-00-32.03.jpg',\n",
              "  'there are many people standing outside together with balloons',\n",
              "  'a crowd of people walking along a street holding balloons',\n",
              "  'a crowd watches a parade down the street'],\n",
              " ['frame0-00-32.20.jpg',\n",
              "  'some people are in front of a large bank',\n",
              "  'a group of people standing in front of a large bank',\n",
              "  'a large group of people with balloons in the air'],\n",
              " ['frame0-00-32.37.jpg',\n",
              "  'a group of people with some balloons around them',\n",
              "  'a large group of people with balloons',\n",
              "  'a large group of people on the street with balloons'],\n",
              " ['frame0-00-32.53.jpg',\n",
              "  'blue balloons float up in the air as people watch from their cars',\n",
              "  'a large crowd in blue hats, on city street',\n",
              "  'a group of people wearing clown hats with blue balloons'],\n",
              " ['frame0-00-32.70.jpg',\n",
              "  'there are people standing on the sidewalk watching balloons blow in the air',\n",
              "  'blue balloons with red tops on people watching them',\n",
              "  'blue balloons are sitting in front of a large crowd'],\n",
              " ['frame0-00-32.87.jpg',\n",
              "  'a large group of people wearing hats and onlookers in front of stores',\n",
              "  'an outside area of the crowd is seen in this image',\n",
              "  'many people walking down the street with balloons'],\n",
              " ['frame0-00-33.03.jpg',\n",
              "  'balloons are floating in the air during a parade',\n",
              "  'a crowd with balloons and people standing around',\n",
              "  'a man holding blue balloons and talking to an audience'],\n",
              " ['frame0-00-33.20.jpg',\n",
              "  'large group of people walking in front of the crowd',\n",
              "  'several people in costumes and holding blue balloons',\n",
              "  'people standing on the side of a road'],\n",
              " ['frame0-00-33.37.jpg',\n",
              "  'a large group of people with balloons at an event',\n",
              "  'a crowded street with blue balloons and some people',\n",
              "  'a crowd is holding up large blue balloons'],\n",
              " ['frame0-00-33.50.jpg',\n",
              "  'the crowds are watching the parade on the street',\n",
              "  'blue balloons float above a crowd of people at an outdoor event',\n",
              "  'group of people with blue balloons in the street'],\n",
              " ['frame0-00-33.67.jpg',\n",
              "  'a crowd of people standing next to each other holding blue balloons',\n",
              "  'there are many balloons at this city street',\n",
              "  'a large group of people with some balloons'],\n",
              " ['frame0-00-33.83.jpg',\n",
              "  'a group of people with blue balloons being watched',\n",
              "  'a crowd of people standing in front of a street filled with balloons',\n",
              "  'a large group of people dressed in clown suits and balloons'],\n",
              " ['frame0-00-34.00.jpg',\n",
              "  'this is a crowd of people with balloons',\n",
              "  'a group of people are dressed in red and yellow',\n",
              "  'a crowd is taking pictures of clowns and balloons'],\n",
              " ['frame0-00-34.17.jpg',\n",
              "  'a group of people gathered around one another on a street',\n",
              "  'a group of people and a few balloons on a street',\n",
              "  'there are people taking pictures of a parade'],\n",
              " ['frame0-00-34.33.jpg',\n",
              "  'a group of people taking pictures of a parade',\n",
              "  'large group of people in costume in the street',\n",
              "  'a crowd that is standing outside by some kind of building'],\n",
              " ['frame0-00-34.50.jpg',\n",
              "  'a group of men standing in front of people',\n",
              "  'a group of people with balloons and floats in the air',\n",
              "  'people are taking pictures while two children are on the street'],\n",
              " ['frame0-00-34.67.jpg',\n",
              "  'a bunch of people are dancing in front of a bank',\n",
              "  'an audience is watching people with red and yellow dress on',\n",
              "  'people in costumes are standing on a street as the crowd looks at them'],\n",
              " ['frame0-00-34.83.jpg',\n",
              "  'a parade with a large crowd of people in red and yellow outfits',\n",
              "  'a group of people standing in front of a crowd',\n",
              "  'crowd at outdoor carnival in front of bank'],\n",
              " ['frame0-00-35.00.jpg',\n",
              "  'people and clowns at carnival with balloons and people watching',\n",
              "  'a large crowd in a street with balloons and people',\n",
              "  'a big crowd of people at an atm']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(rows, columns=fields, dtype=float)\n",
        "df.to_csv(frames_dir + \"_captions.csv\")"
      ],
      "metadata": {
        "id": "hgycphWk8-mX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996aed75-8baa-47f0-df65-0e0518072eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt')\n",
        "cfg = BEATsConfig(checkpoint['cfg'])\n",
        "BEATs_model = BEATs(cfg)\n",
        "BEATs_model.load_state_dict(checkpoint['model'])"
      ],
      "metadata": {
        "id": "2Q5LE8fWOrlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b45662-83a2-4a59-9845-a014c49b5269"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_labels(audio_input_16khz, k):\n",
        "  audio_length = audio_input_16khz.shape[1]\n",
        "  audio_dim = audio_input_16khz.shape[0]\n",
        "  padding_mask = torch.zeros(audio_dim,audio_length).bool()\n",
        "\n",
        "  probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
        "  for i, (top5_label_prob, top5_label_idx) in enumerate(zip(*probs.topk(k=k))):\n",
        "      top5_label = [checkpoint['label_dict'][label_idx.item()] for label_idx in top5_label_idx]\n",
        "      return (top5_label, top5_label_prob)\n",
        "\n",
        "def plot_2_cols(df, lab1, lab2, kind='line'):\n",
        "  ax = df.plot(y=lab1, legend=False, kind=kind)\n",
        "  ax2 = ax.twinx()\n",
        "  df.plot(y=lab2, ax=ax2, legend=False, color=\"c\", kind=kind)\n",
        "  ax.figure.legend()\n",
        "  plt.show()\n",
        "\n",
        "class Video:\n",
        "  def __init__(self, vid_name):\n",
        "    self.name = vid_name\n",
        "    meta = torchaudio.info(vid_name + '.wav') # load in wav fie for number of frames\n",
        "    self.num_frames = meta.num_frames # get number of frames total\n",
        "    self.waveform, self.sample_rate = torchaudio.load(vid_name + '.wav')\n",
        "    self.slice_waveform() # get cut up waveforms\n",
        "    cap = cv2.VideoCapture(vid_name+'.mp4')\n",
        "    self.fps = cap.get(cv2.CAP_PROP_FPS) # get fps through openCV\n",
        "  def slice_waveform(self):\n",
        "    scaler = 2*self.sample_rate\n",
        "    i_range = range(math.ceil(self.num_frames/scaler))\n",
        "    def bot_slice(i):\n",
        "      return i*scaler\n",
        "    def top_slice(i):\n",
        "      return min((i+1)*scaler, self.num_frames)\n",
        "    self.waveforms = [self.waveform[:,bot_slice(i):top_slice(i)] for i in i_range]\n",
        "    self.num_slices = len(self.waveforms)\n",
        "  def get_k_labels(self, k):\n",
        "    self.k = k\n",
        "    self.labels = [get_top_k_labels(wave, k) for wave in self.waveforms]\n",
        "    label_set = [label[0] for label in self.labels]\n",
        "    ont_index = lambda label: next((i for i, item in enumerate(ontology) if item['id'] == label), -1)\n",
        "    a = lambda x: [ontology[ont_index(i)]['name'] for i in x]\n",
        "    self.english_labels = pd.DataFrame([a(label) for label in label_set])\n",
        "  def get_scores(self):\n",
        "    vid_anno = anno.loc[anno[0] == self.name]\n",
        "    a = lambda x: [int(i) for i in x[1][2].split(',')]\n",
        "    b = lambda x: pd.DataFrame([a(i) for i in vid_anno.iterrows()])\n",
        "    # def annotation_string_to_numerics(vid_anno): \n",
        "      # return pd.DataFrame([a(annotation) for annotation in vid_anno.iterrows()])\n",
        "    self.ratings = b(vid_anno)\n",
        "    scaler = 2*self.fps\n",
        "    i_range = range(1,math.ceil(self.ratings.shape[1]/scaler))\n",
        "    def bot_slice(i):\n",
        "      return int(i*scaler)\n",
        "    # def top_slice(i):\n",
        "      # return min((i+1)*scaler, ratings.shape[1])\n",
        "\n",
        "    abs_scorer = lambda i: sum(abs(self.ratings[bot_slice(i)] - self.ratings[bot_slice(i)+1]))\n",
        "    abs_score_changes = pd.DataFrame([abs_scorer(i) for i in i_range])\n",
        "\n",
        "    scorer = lambda i: sum(self.ratings[bot_slice(i)] - self.ratings[bot_slice(i)+1])\n",
        "    score_changes = pd.DataFrame([scorer(i) for i in i_range])\n",
        "\n",
        "    changes = pd.concat([abs_score_changes, score_changes], axis=1)\n",
        "    changes.columns = ['Abs Score','Score']\n",
        "    self.changes = changes\n",
        "\n",
        "    a = lambda ind, df: pd.Series(df.iloc[ind])\n",
        "    b = lambda ind, df: len(a(ind, df)) - sum([(item in a(ind+1, df).unique()) for item in a(ind, df)]) \n",
        "    label_changes = lambda df: pd.DataFrame([b(i, df) for i in range(df.shape[0]-1)])\n",
        "    for i in range(1,self.k+1):\n",
        "      lab_changes = label_changes(self.english_labels.iloc[:,0:i])\n",
        "      self.changes[str(i)+'Labels'] = lab_changes\n",
        "\n",
        "    \n",
        "  # def get_scores(self)\n",
        "  "
      ],
      "metadata": {
        "id": "pvYUnyg59JY2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Video(vid_name='91IHQYk1IQM')\n",
        "a.get_k_labels(5)\n",
        "a.get_scores()"
      ],
      "metadata": {
        "id": "-IaWyKZc-PXU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def templater(audio, visual, scores, fps, k):\n",
        "  combined_labs = []\n",
        "  aligned_scores = []\n",
        "\n",
        "  scaler = 2*fps\n",
        "  i_range = range(0,math.ceil(scores.shape[1]/scaler))\n",
        "  def bot_slice(i):\n",
        "    return int(i*scaler)\n",
        "  scorer = lambda i: a.ratings[bot_slice(i)].mean()\n",
        "  avg_scores = pd.Series([scorer(i) for i in i_range])\n",
        "  for x in visual.iterrows():\n",
        "    frame_time = str(x[1][0])[5:-7]\n",
        "    frame_times = [int(x) for x in frame_time.split('-')]\n",
        "    total_frame_times = frame_times[0]*60**2 + frame_times[1]*60 + frame_times[2]\n",
        "    audio_ind = min(int(total_frame_times/2), a.english_labels.shape[0])\n",
        "    audio_labs_list = audio.iloc[audio_ind]\n",
        "    audio_labs = \"\"\n",
        "    for i in range(0,k):\n",
        "      lab = audio_labs_list[i].lower()\n",
        "      if(i < k-1):\n",
        "        audio_labs += lab + \", \"\n",
        "      elif k == 1:\n",
        "        audio_labs += lab\n",
        "      else:\n",
        "        audio_labs += \"and \" + lab\n",
        "    \n",
        "    visual_lab = x[1][1]\n",
        "\n",
        "    \n",
        "    aligned_scores.append(avg_scores[audio_ind])\n",
        "    combined_labs.append(\"You hear \" + audio_labs + \" and see \" + visual_lab)\n",
        "  return pd.DataFrame([combined_labs, aligned_scores]).transpose()"
      ],
      "metadata": {
        "id": "kt33pw0eS9kk"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "templated_df = templater(a.english_labels, df, a.ratings, a.fps, k=3)\n",
        "templated_df.to_csv(a.name+\"_templated.csv\")\n",
        "templated_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2QCYuRQYWCvU",
        "outputId": "a5f9dba5-6719-4ab1-b92d-d9acb3e6de21"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0    1\n",
              "0    You hear music, violin, fiddle, and musical in...  1.7\n",
              "1    You hear music, violin, fiddle, and musical in...  1.7\n",
              "2    You hear music, violin, fiddle, and musical in...  1.7\n",
              "3    You hear music, violin, fiddle, and musical in...  1.7\n",
              "4    You hear music, violin, fiddle, and musical in...  1.7\n",
              "..                                                 ...  ...\n",
              "206  You hear music, drum, and speech and see a gro...  1.8\n",
              "207  You hear music, drum, and speech and see a gro...  1.8\n",
              "208  You hear music, drum, and speech and see a bun...  1.8\n",
              "209  You hear music, drum, and speech and see a par...  1.8\n",
              "210  You hear music, drum, and speech and see peopl...  1.8\n",
              "\n",
              "[211 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fa79702-3ffc-464e-bb98-a2e1a94aaadf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You hear music, violin, fiddle, and musical in...</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You hear music, violin, fiddle, and musical in...</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You hear music, violin, fiddle, and musical in...</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You hear music, violin, fiddle, and musical in...</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You hear music, violin, fiddle, and musical in...</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>You hear music, drum, and speech and see a gro...</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>You hear music, drum, and speech and see a gro...</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>You hear music, drum, and speech and see a bun...</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>You hear music, drum, and speech and see a par...</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>You hear music, drum, and speech and see peopl...</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fa79702-3ffc-464e-bb98-a2e1a94aaadf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fa79702-3ffc-464e-bb98-a2e1a94aaadf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fa79702-3ffc-464e-bb98-a2e1a94aaadf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    }
  ]
}